{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic programming II: sequential cotinuous choice\n",
    "ECON 3127/4414/8014 Computational methods in economics  \n",
    "Week 10  \n",
    "Fedor Iskhakov  \n",
    "<img src=\"../img/lecture.png\" width=\"64px\"/>\n",
    "\n",
    "&#128214; Adda and Russell Cooper \"Dynamic Economics. Quantitative Methods and Applications.\"\n",
    "    *Chapters: 2,3*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan for the lecture\n",
    "1. Recap of last lecture on DP\n",
    "2. Contraction mappings and fixed point theory\n",
    "3. Cake eating problems in various formulations\n",
    "4. Corresponding solution methods\n",
    "5. Lab tomorrow: practice of formulating and solving a DP problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: What is Dynamic Programming\n",
    "**DP is a general algorithm design technique for solving problems with overlapping sub-problems.**\n",
    "\n",
    "**\"DP is recursive method for solving sequential decision problems\"**  \n",
    "&#128214; Rust 2006, _New Palgrave Dictionary of Economics_\n",
    "\n",
    "**Bellman's Principle of Optimality**\n",
    "\"An optimal policy has a property that whatever the initial state and initial decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.\"  \n",
    "&#128214; Bellman, 1957 \"Dynamic Programming\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Dynamic programming in economics\n",
    "Macro:\n",
    "- Stochastic growth models\n",
    "- Consumption and savings\n",
    "- Investment\n",
    "- Heterogeneous agents and overlapping generaton models\n",
    "\n",
    "Micro:\n",
    "- Dynamic models of labor supply and job search\n",
    "- Human capital accumulation\n",
    "- Health process, insurance and long term care\n",
    "- Durable consumption\n",
    "- Numerical solutions to game-theoretic models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Components of DP problem\n",
    "- **State variables**  — vector of variables that describe all relevant information about the modeled decision process\n",
    "- **Decision variables** — vector of variables describing the choices\n",
    "- **Instantaneous payoff** — utility function, additively separable across time periods\n",
    "- **Motion rules** — agent's beliefs of how state variable evolve through time, conditional on choices (controlled Markov process in Markovian problems)\n",
    "- **Value function** — maximum attainable utility at any point of the state space (and time period)\n",
    "- **Policy function** — mapping from state space to action space that returns the optimal choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bellman equation (finite horizon)\n",
    "\n",
    "\\begin{eqnarray}\n",
    "V_t(x_t) &=& \n",
    "\\max_{\\sigma_t \\in \\Sigma_t} \\Big\\{ u_t\\big(x_t,d_t\\big) \n",
    "+ \\beta \\mathbb{E}_t \\big[ V_{t+1}(x_{t+1})  \\big| x_t, d_t \\big] \\Big\\}, t<T\n",
    "\\\\\n",
    "V_T(x_T) &=& \n",
    "\\max_{\\sigma_T \\in \\Sigma_T} \\Big\\{ u_T\\big(x_T,d_T\\big) \\Big\\}\n",
    "\\end{eqnarray}\n",
    "\n",
    "- $t$ index of __time period__, $t=1,\\dots,T$\n",
    "- $x_t \\in S$ state variables\n",
    "- $d_t \\in D$ decision varibles, $d_t=\\sigma_t(x_t), t=1,\\dots,T$\n",
    "- $\\sigma_t(x_t): S\\rightarrow D$ policy function from __feasible__ set $\\Sigma_t$\n",
    "- $\\mathbb{E}_t$ conditional expectation given $t$-motion rule\n",
    "- time indexes can be dropped for the time-invariant elements\n",
    "- solution is a __collection__ of policy functions $\\{\\sigma_t(x_t)\\}_{t=1,\\dots,T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bellman equation (infinite horizon)\n",
    "\n",
    "$$\n",
    "V(x) =\n",
    "\\max_{\\sigma \\in \\Sigma} \\Big\\{ u\\big(x,d\\big) \n",
    "+ \\beta \\mathbb{E} \\big[ V(x')  \\big| x, d \\big] \\Big\\}\n",
    "$$\n",
    "\n",
    "- $x,x' \\in S$ state variables, $x'$ is next period state\n",
    "- $d \\in D$ decision varibles, $d=\\sigma(x)$\n",
    "- $\\sigma(x): S\\rightarrow D$ policy function from __feasible__ set $\\Sigma$\n",
    "- solution is a __single__ of policy functions $\\{\\sigma_t(x_t)\\}_{t=1,\\dots,T}$\n",
    "- fixed point problem for value function $V(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is value function?\n",
    "\n",
    "\\begin{eqnarray}\n",
    "V(x) &=& \n",
    "\\max_{\\sigma \\in \\Sigma} \\Big\\{ u\\big(x,d\\big) \n",
    "+ \\beta \\mathbb{E} \\big[ V(x')  \\big| x, d \\big] \\Big\\}\n",
    "\\\\\n",
    "&=& \n",
    "\\max_{\\sigma \\in \\Sigma} \\Big\\{ u\\big(x,d\\big) \n",
    "+ \\beta \\mathbb{E} \\big[ \n",
    "\\max_{\\sigma \\in \\Sigma} \\Big\\{ u\\big(x',d'\\big) \n",
    "+ \\beta \\mathbb{E} \\big[ V(x'')  \\big| x', d' \\big] \\Big\\}\n",
    "\\big| x, d \\big] \\Big\\}\n",
    "\\\\\n",
    "&\\dots&\\\\\n",
    "&=&\n",
    "\\max_{\\sigma \\in \\Sigma} \\mathbb{E} \\sum_{t=0}^{\\infty} \\beta^t u\\big(x,\\sigma(x)\\big) \n",
    "\\end{eqnarray}\n",
    "\n",
    "Maximum expected utility at each point of state space (both infinite and finite horizon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important characteristics of DP problems\n",
    "1. Dimensions/cardinality of states and choices\n",
    "1. Finite / infinite horizon\n",
    "1. Discrete / continuous / discrete-continuous choice\n",
    "1. Discrete / continuous states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution methods\n",
    "Finite horizon $\\leftrightarrow$ recursive computation\n",
    "1. Backward induction = VFI without fixed point\n",
    "\n",
    "Infinite horizon $\\leftrightarrow$ fixed point problem\n",
    "1. Value fucntion iterations (VFI) = back.ind. with convergence\n",
    "2. Policy iterations\n",
    "3. Combination of the two (Newton-Kantorovich step)\n",
    "\n",
    "Plus special methods for particular model classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Infinite horizon $\\leftrightarrow$ fixed point problem\n",
    "\n",
    "**Contraction mapping**\n",
    "\n",
    "Let $(S,\\rho)$ be a metric space, and $T: S \\rightarrow S$.\n",
    "The mapping $T$ is _contraction mapping_ if\n",
    "\n",
    "$$\n",
    "||T(s)-T(s')|| < ||s-s'|| \\text{ for } \\forall s \\ne s' \\in S,\n",
    "$$\n",
    "\n",
    "where $||\\cdot||$ is the norm that generates metric $\\rho$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Value of annuity\n",
    "\n",
    "$$\n",
    "\\stackrel{\\nearrow}{V} \\quad\n",
    "\\stackrel{\\searrow}{c} \\quad\n",
    "\\stackrel{\\searrow}{c} \\quad\n",
    "\\stackrel{\\searrow}{c} \\quad\n",
    "\\dots\n",
    "$$\n",
    "\n",
    "$$\n",
    "V=\\quad\n",
    "\\frac{c}{(1+r)^0} + \\quad\n",
    "\\frac{c}{(1+r)^1} + \\quad\n",
    "\\frac{c}{(1+r)^2} + \\quad\n",
    "\\frac{c}{(1+r)^3} + \\quad\n",
    "\\dots\n",
    "$$\n",
    "\n",
    "- interest rate $r$\n",
    "- $V$ can be found from the \"Bellman equation\"\n",
    "\n",
    "$$\n",
    "V = c + \\frac{1}{1+r} V = T(V)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward induction/VFI algorithm\n",
    "\n",
    "1. Start with a guess $V_0$\n",
    "2. Insert into the Bellman equation\n",
    "\n",
    "$$\n",
    "V_{i+1} = c + \\frac{1}{1+r} V_i = T(V_i)\n",
    "$$\n",
    "\n",
    "3. Repeat until convergence\n",
    "\n",
    "$$\n",
    "||V_{i}-V_{i-1}||\\leq\\varepsilon\\text{ (small number)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Contraction mapping?\n",
    "\n",
    "\n",
    "$$\n",
    "||V_{i}-V_{i-1}|| = ||(c+\\beta V_{i-1})-(c+\\beta V_{i-2})||=\\beta ||V_{i-1}-V_{i-2}||\n",
    "$$\n",
    "\n",
    "- If $\\beta<1$ with every iteration the difference $||V_{i}-V_{i-1}||$ becomes **strictly smaller**\n",
    "- Recursive formula (Bellman equation) is **contraction mapping**\n",
    "- Banach fixed point theorem guarantees unique solution!\n",
    "\n",
    "$$\n",
    "V'=T(V) \\; \\Rightarrow ||T(V')-T(V)|| = \\beta ||V'-V|| < ||V'-V||\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Blackwell conditions for contraction mapping\n",
    "\n",
    "Let $B(\\mathbb{R}^n,\\mathbb{R})$ be a set of bounded functions $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, with the sup norm. If an operator $T:B(\\mathbb{R}^n,\\mathbb{R}) \\rightarrow B(\\mathbb{R}^n,\\mathbb{R})$ satisfies\n",
    "1. Monotonicity\n",
    "$$\n",
    "\\forall f,g \\in B(\\mathbb{R}^n,\\mathbb{R}), f(x)\\le g(x) \\forall x \\Longrightarrow Tf(x) \\le Tg(x) \\forall x,\n",
    "$$\n",
    "2. Discounding\n",
    "$$\n",
    "\\exists \\beta \\in (0,1) \\text{ such that } \\forall f \\in B(\\mathbb{R}^n,\\mathbb{R}), x \\in  \\mathbb{R}^n,\n",
    "\\text{ and } \\alpha>0\n",
    "$$\n",
    "$$\n",
    "\\text {we have } T\\big( f(x) + \\alpha \\big) \\le  T\\big( f(x)  \\big) + \\beta\\alpha,\n",
    "$$\n",
    "\n",
    "then $T$ is a contraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Blackwell conditions apply for Bellman equation\n",
    "\n",
    "Assuming the utility if bounded:\n",
    "\n",
    "1. Monotonicity is satisfied due to maximization inside $T(V)$\n",
    "2. Discounting is satisfied by elementary argument when $\\beta<1$\n",
    "\n",
    "**The Bellman operator is contraction mapping under typical conditions!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Banach fixed point theorem\n",
    "\n",
    "Let $(S,\\rho)$ be a complete metric space with a contraction mapping $T: S \\rightarrow S$.\n",
    "Then \n",
    "1. $T$ admits a unique fixed-point $V^{\\star} \\in S$, i.e. $T(V^{\\star}) = V^{\\star}$. \n",
    "2. $V^{\\star}$ can be found by repeated application of the operator $T$, i.e. $T^n(V) \\rightarrow V^{\\star}$ as $n\\rightarrow \\infty$.\n",
    "\n",
    "**Global solution method for infinite horizon DP problems!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cake eating problem\n",
    "\n",
    "![cake](img/cake.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/cake.png\" width=100px>\n",
    "- Cake of initial size $W_0$\n",
    "- **How much of the cake to eat each period $t$?**\n",
    "- Time is discrete, $t=1,2,\\dots$\n",
    "- What is not eaten in period $t$ is left for the future\n",
    "\n",
    "$$W_{t+1}=W_t-c_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/cake.png\" width=100px>\n",
    "- Utility flow from cake consumption\n",
    "\n",
    "$$\n",
    "u(c_{t})=\\log(c_t)\n",
    "$$\n",
    "\n",
    "- Future is discounted with discount factor $\\beta$\n",
    "- Optimization problem: \n",
    "\n",
    "$$\n",
    "\\max_{\\{c_{t}\\}_{0}^{\\infty}}\\sum_{t=0}^{\\infty}\\beta^{t}u(c_{t})\n",
    "\\longrightarrow \\max\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/cake.png\" width=100px>\n",
    "**Value function $V(W_t)$** = the maximum attainable value given the size of cake $W_t$ (in period $t$)\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "  V(W_{0}) & = & \\max_{\\{c_{t}\\}_{0}^{\\infty}}\\sum_{t=0}^{\\infty}\\beta^{t}u(c_{t})\\\\\n",
    "  & = & \\max_{c_{0}}\\{u(c_{0})+\\beta\\max_{\\{c_{t}\\}_{1}^{\\infty}}\\sum_{t=1}^{\\infty}\\beta^{t-1}u(c_{t})\\}\\\\\n",
    "  & = & \\max_{c_{0}}\\{u(c_{0})+\\beta V(W_{1})\\}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/cake.png\" width=100px>\n",
    "**Bellman equation**\n",
    "\n",
    "$$\n",
    "V(W_{t})=\\max_{0 \\le c_{t} \\le W_t}\\big\\{u(c_{t})+\\beta V(\\underset{=W_{t}-c_{t}}{\\underbrace{W_{t+1}}})\\big\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **State variables**  — vector of variables that describe all relevant information about the modeled decision process, $W_t$\n",
    "- **Decision variables** — vector of variables describing the choices, $c_t$\n",
    "- **Instantaneous payoff** — utility function, $u(c_t)$, with time separable discounted utility\n",
    "- **Motion rules** — agent's beliefs of how state variable evolve through time, conditional on choices, $W_{t+1}=W_t-c_t$\n",
    "- **Value function** — maximum attainable utility, $V(W_t)$\n",
    "- **Policy function** — mapping from state space to action space that returns the optimal choice, $c^{\\star}(W_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cake eating: analytic solution\n",
    "- Start with a (good) guess of $V(W)=A+B\\log W$\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "  V(W) & = & \\max_{c}\\big\\{u(c)+\\beta V(W-c)\\big\\} \\\\\n",
    "  A+B\\log W & = & \\max_{c} \\big\\{\\log c+\\beta(A+B\\log (W-c)) \\big\\}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "- Determine $A$ and $B$ and find the optimal rule for cake consumption.\n",
    "- This is only possible in **few** models!\n",
    "\n",
    "$$\n",
    "c^{\\star}(W) = \\arg\\max_{c}\\big\\{\\log(c)+\\beta V(W-c)\\big\\} = (1-\\beta)W\n",
    "$$\n",
    "\n",
    "$$\n",
    "A=\\frac{\\log(1-\\beta)}{1-\\beta} + \\frac{\\beta \\log(\\beta)}{(1-\\beta)^2},\\quad\n",
    "B=\\frac{1}{1-\\beta}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cake eating: numeric solution\n",
    "- Have to solve the _functional equation_ for $V(W)$\n",
    "- The Bellman operator in functional space\n",
    "$$\n",
    "T({V})(W) \\equiv \\max_{0 \\le c \\le W}\\{u(c)+\\beta {V}(W-c)\\}\n",
    "$$\n",
    "\n",
    "\n",
    "- The Bellman equations is then $V(W) = T({V})(W)$, with the solution given by the fixed point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Can we find the fixed point by iterations?\n",
    "\n",
    "**Standard fixed point argument applies**\n",
    "\n",
    "- Bellman operator is contraction mapping $\\Rightarrow$\n",
    "- Unique fixed point $\\Leftrightarrow$ unique solution to the Bellman equation\n",
    "- The fixed point can be reached by an iterative process using an **arbitrary\n",
    "initial guess**!\n",
    "- Therefore VFI algorithm converges globally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Value function iterations (VFI)\n",
    "1. Start with an arbitrary guess $V_0(W)$\n",
    "2. At each iteration $i$ compute \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "V_i(W) = T(V_{i-1})(W) &=& \n",
    "\\max_{0 \\le c \\le W} \\big\\{u(c)+\\beta V_{i-1}(W-c) \\big \\}  \\\\\n",
    "c_{i-1}(W) &=& \n",
    "\\underset{0 \\le c \\le W}{\\arg\\max} \\big\\{u(c)+\\beta V_{i-1}(W-c) \\big \\} \n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "3. Repeat until convergence \n",
    "\n",
    "$$\n",
    "||V_{i}(W)-V_{i-1}(W)||\\leq\\varepsilon\\text{ (small number,} ||\\cdot|| \\text{ sup norm)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numerical implementation of the Bellman operator\n",
    "- Cake is continuous $\\rightarrow$ value function is a function of continuous variable\n",
    "- Solution: **discretize $W$**  \n",
    "Construct a _grid_ (vector) of cake-sizes  $\\vec{W}\\in\\{0,\\dots\\overline{W}\\}$\n",
    "\n",
    "$$V_{i}(\\vec{W})=\\max_{0 \\le c \\le \\vec{W}}\\{u(c)+\\beta V_{i-1}(\\vec{W}-c)\\}$$\n",
    "\n",
    "- Compute value and policy function sequentially point-by-point\n",
    "- May need to compute the value function _between grid points_\n",
    "$\\Rightarrow$\n",
    "Interpolation and function approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Can interpolation be avoided?\n",
    "- Note that conditional on $W_t$, the choice of $c$ defines $W_{t+1}$ \n",
    "- Can replace $c$ with $W_{t+1}$ in Bellman equation so that _next period cake size is the decision variable_\n",
    "- \"Dual\" formulation of the same problem \n",
    "\n",
    "$$\n",
    "V_{i}(\\vec{W})=\\max_{0 \\le \\vec{W}' \\le \\vec{W}}\\{u(\\vec{W}-\\vec{W}')+\\beta V_{i-1}(\\vec{W}')\\}\n",
    "$$\n",
    "\n",
    "- Compute value and policy function sequentially point-by-point\n",
    "- Note that grid $\\vec{W}\\in\\{0,\\dots\\overline{W}\\}$ is used twice: for state space and for decision space\n",
    "- _Can you spot the potential problem?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# plotting parameters\n",
    "plt.rcParams['axes.autolimit_mode'] = 'round_numbers'\n",
    "plt.rcParams['axes.xmargin'] = 0\n",
    "plt.rcParams['axes.ymargin'] = 0\n",
    "plt.rcParams['patch.force_edgecolor'] = True\n",
    "from cycler import cycler\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color='bgrcmyk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class cake:\n",
    "    '''Cake eating model fundamentals'''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''Cake eating default parameters'''\n",
    "        self.beta=.9        # Discount factor\n",
    "        self.Wbar=10        # Upper bound on cake size\n",
    "        self.ngrid=100      # Number of grid points\n",
    "        self.ngridd=500     # Number of grid points for decisions\n",
    "        self.maxiter=1000   # Maximum number of iterations\n",
    "        self.tol=1e-4       # Convergence tolerance\n",
    "        # analytical solution\n",
    "        self.apolicy = lambda w: w*(1-self.beta) \n",
    "        self.avalue = lambda w: np.log(1-self.beta)/(1-self.beta) + self.beta*np.log(self.beta)/((1-self.beta)**2) + np.log(w)/(1-self.beta)\n",
    "        \n",
    "    def utility(self,x):\n",
    "        '''Utility function'''\n",
    "        return np.log(x)    \n",
    "    \n",
    "    def marginal_utility(self,x):\n",
    "        '''Marginal utility function'''\n",
    "        return 1/x\n",
    "    \n",
    "    def inverse_marginal_utility(self,x):\n",
    "        '''Inverse marginal utility function'''\n",
    "        return 1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def solve1(model,plotting=True):\n",
    "    '''Solve cake eating problem on-the-grid'''\n",
    "    machine_epsilon=np.finfo(float).eps #smallest positive float number\n",
    "    ngrid=model.ngrid\n",
    "    #(1 by ngrid) grid for both state and decision space\n",
    "    grid=np.linspace(machine_epsilon,model.Wbar,ngrid).reshape(1,ngrid)\n",
    "    \n",
    "    def bellman(V0):\n",
    "        '''Bellman operator for on-the-grid solution'''\n",
    "        #V0 should be vector-row of values on grid\n",
    "        matW=np.repeat(grid,ngrid,0) #matrix with state space repeated in rows\n",
    "        matWpr=np.repeat(np.transpose(grid),ngrid,1) #matrix with decision space repeated in columns\n",
    "        matV0=np.repeat(np.transpose(V0),ngrid,1) #current value function repeated in columns\n",
    "        c=matW-matWpr #level of cake consumtpion in current period\n",
    "        c[c==0]=machine_epsilon #add small quantity to avoid log(0)\n",
    "        mask=c>0 #mask off infeasible choices\n",
    "        preV=-np.inf*np.ones((ngrid,ngrid)) #prepare space for trial values for all possible choices\n",
    "        preV[mask]=model.utility(c[mask])+model.beta*matV0[mask] #maximand of the Bellman equation\n",
    "        V1=np.amax(preV,0,keepdims=True) #maximum in every column\n",
    "        ic=np.argmax(preV,axis=0) #index of arg-maximum in every column\n",
    "        cstar=c[ic,range(ngrid)].reshape((1,ngrid))\n",
    "        return V1, cstar\n",
    "\n",
    "    if plotting:\n",
    "        # prepare to make plots \n",
    "        fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "        plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax1.set_title('Value function convergence with VFI')\n",
    "        ax1.set_xlabel('Cake size, W')\n",
    "        ax1.set_ylabel('Value function')\n",
    "    \n",
    "    V0=np.zeros((1,model.ngrid)) #initial value function\n",
    "    for i in range(model.maxiter):\n",
    "        V1,c=bellman(V0)\n",
    "        if plotting and (i%5==0):\n",
    "            # plot all but the first point for better viewing\n",
    "            ax1.plot(np.squeeze(grid[0,1:]),np.squeeze(V1[0,1:]),linewidth=2.5)\n",
    "        if np.max(abs(V1-V0))<model.tol:\n",
    "            print('Convergence achieved after %d iterations'%i)\n",
    "            break\n",
    "        V0=V1\n",
    "    else:\n",
    "        print('No convergence in %d iterations: maximum number of iterations achieved'%model.maxiter)\n",
    "    return grid, V1, c\n",
    "\n",
    "m = cake()\n",
    "w,v,c = solve1(m)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to measure numerical errors?\n",
    "- In our case there is an analytic solution\n",
    "- Typically very dense (slow) grid is used in place of true solution\n",
    "- Can control for max or mean error at the grid points of value and policy functions\n",
    "- Better yet: simulations of the known analytic cases (Keane's test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m = cake()\n",
    "# m.ngrid=100\n",
    "w,v,c = solve1(m,plotting=False)\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Value function')\n",
    "ax1.plot(w[0,1:].squeeze(),v[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.avalue(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Policy function')\n",
    "ax1.plot(w[0,1:].squeeze(),c[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.apolicy(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cake eating with discretized choices\n",
    "\n",
    "_Control for grid over state space separately from the discretization of the choice variables to increase accuracy_\n",
    "\n",
    "- As before solve cake eating Bellman equation by VFI\n",
    "\n",
    "$$V(W) = \\max_{0 \\le c \\le W} \\big\\{u(c)+\\beta V(W-c) \\big \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Discretize state space with $\\vec{W}\\in\\{0,\\dots\\overline{W}\\}$\n",
    "\n",
    "- Discretize decision space with $\\vec{D}\\in\\{0,\\dots\\overline{D}\\}$, usually $\\overline{D}=\\overline{W}$\n",
    "\n",
    "$$V_{i}(\\vec{W})=\\max_{0 \\le \\vec{D} \\le \\vec{W}}\\{u(c)+\\beta V_{i-1}(\\vec{W}-c)\\}$$\n",
    "\n",
    "- Compute value/policy function point-by-point on grid $\\vec{W}$\n",
    "- Find the maximum over the points of grid $\\vec{D}$ that satisfy the choice set condition $0 \\le \\vec{D} \\le W$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Need interpolation\n",
    "- In each iteration, the value function $V_{i}(\\vec{W})$ is computed on a set of grid points\n",
    "- But for iteration $i+1$ we need to compute $V_{i}(\\vec{W}-c)\\}=V_{i}(\\vec{W}-\\vec{D})\\}$\n",
    "- **Interpolation of the value function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def solve2(model,plotting=True):\n",
    "    '''Solve cake eating problem by discretization'''\n",
    "    machine_epsilon=np.finfo(float).eps #smallest positive float number\n",
    "    ngrid=model.ngrid\n",
    "    ngrid_decision=model.ngridd\n",
    "    #(1 by ngrid) grid for state space only\n",
    "    grid=np.linspace(machine_epsilon,model.Wbar,ngrid).reshape(1,ngrid)\n",
    "    #(ngrid_decision by ngrid) grids of decisions between 0 and each w on grid\n",
    "    grid_decision=np.zeros((ngrid_decision,ngrid)) #allocate space\n",
    "    for i,x in zip(range(ngrid),grid.squeeze()):\n",
    "        grid_decision[:,i]=np.linspace(machine_epsilon,x,ngrid_decision)\n",
    "        \n",
    "    def bellman(V0):\n",
    "        '''Bellman operator for discretized solution'''\n",
    "        #V0 should be vector-row of values on grid\n",
    "        matW=np.repeat(grid,ngrid_decision,0) #matrix with state space repeated in rows\n",
    "        c=grid_decision #decisions grid in columns\n",
    "        matWpr=matW-c #size of cake in the next period\n",
    "        matWpr[matWpr==0]=machine_epsilon #add small quantity to avoid log(0)\n",
    "        mask=matWpr>0 #mask off infeasible choices\n",
    "        matV=np.interp(matWpr,np.squeeze(grid),np.squeeze(V0)) #values of next period value at next period case sizes\n",
    "        preV=-np.inf*np.ones((ngrid_decision,ngrid)) #prepare space for trial values for all possible choices\n",
    "        preV[mask]=model.utility(c[mask])+model.beta*matV[mask] #maximand of the Bellman equation\n",
    "        V1=np.amax(preV,0,keepdims=True) #maximum in every column\n",
    "        ic=np.argmax(preV,axis=0) #index of arg-maximum in every column\n",
    "        cstar=c[ic,range(ngrid)].reshape((1,ngrid))\n",
    "        return V1, cstar\n",
    "    \n",
    "    if plotting:\n",
    "        # prepare to make plots \n",
    "        fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "        plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax1.set_title('Value function convergence with VFI')\n",
    "        ax1.set_xlabel('Cake size, W')\n",
    "        ax1.set_ylabel('Value function')\n",
    "    \n",
    "    V0=np.zeros((1,model.ngrid)) #initial value function\n",
    "    for i in range(model.maxiter):\n",
    "        V1,c=bellman(V0)\n",
    "        if plotting and (i%5==0):\n",
    "            # plot all but the first point for better viewing\n",
    "            ax1.plot(np.squeeze(grid[0][1:]),np.squeeze(V1[0][1:]),linewidth=2.5)\n",
    "        if np.max(abs(V1-V0))<model.tol:\n",
    "            print('Convergence achieved after %d iterations'%i)\n",
    "            break\n",
    "        V0=V1\n",
    "    else:\n",
    "        print('No convergence in %d iterations: maximum number of iterations achieved'%model.maxiter)\n",
    "    return grid, V1, c\n",
    "\n",
    "m = cake()\n",
    "w,v,c = solve2(m)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m = cake()\n",
    "# m.beta=0.9925\n",
    "# m.ngrid=500\n",
    "# m.ngridd=200\n",
    "w,v,c = solve2(m,plotting=False)\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Value function')\n",
    "ax1.plot(w[0,1:].squeeze(),v[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.avalue(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Policy function')\n",
    "ax1.plot(w[0,1:].squeeze(),c[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.apolicy(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why the results so different?\n",
    "- Solving \"on the grid\" impies very coarse discretization of consumption for higher levels of wealth..\n",
    "- Errors accumulate in the backwards induction and VFI\n",
    "- Discrepancy depends on the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous choice\n",
    "\n",
    "**Can we avoid discretization of consumption altogether? Yes!**\n",
    "\n",
    "- Discretize only the state space $W$\n",
    "\n",
    "$$\n",
    "V_{i}(\\vec{W})=\\max_{0 \\le c \\le \\vec{W}}\\{u(c)+\\beta V_{i-1}(\\vec{W}-c)\\}\n",
    "$$\n",
    "\n",
    "- Treat choices as continuous $\\rightarrow$ optimization problem for each point of $\\vec{W}$\n",
    "- Again, compute value and policy function sequentially point-by-point\n",
    "- Need to compute the value function _between grid points_ $\\rightarrow$ \n",
    "again, interpolation and function approximation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "def solve3(model,plotting=True):\n",
    "    '''Solve cake eating problem with truely continuous consumption'''\n",
    "    machine_epsilon=np.finfo(float).eps #smallest positive float number\n",
    "    ngrid=model.ngrid\n",
    "    #(1 by ngrid) grid for state space only\n",
    "    grid=np.linspace(machine_epsilon,model.Wbar,ngrid).reshape(1,ngrid)\n",
    "        \n",
    "    def bellman(V0):\n",
    "        '''Bellman operator for continuous consumption and Newton'''\n",
    "        cstar=np.zeros((1,ngrid)) #allocate space for optimal choices\n",
    "        V1=np.zeros((1,ngrid)) #allocate space for values\n",
    "        # first point without optimization\n",
    "        cstar[0,0]=machine_epsilon\n",
    "        V1[0,0]=model.utility(machine_epsilon)+model.beta*V0[0,0]\n",
    "        x0=np.average(grid[0,0:2]) #initial starting value\n",
    "        # look for all points except first\n",
    "        for i in np.arange(1,ngrid):\n",
    "            W = grid[0,i]\n",
    "            maximand = lambda c: -(model.utility(c)+model.beta*np.interp(W-c,np.squeeze(grid),np.squeeze(V0)))\n",
    "            cnstr1 = lambda c: c - machine_epsilon \n",
    "            cnstr2 = lambda c: W - c\n",
    "            cnstrs=[{'type':'ineq','fun':cnstr1},\n",
    "                    {'type':'ineq','fun':cnstr2}]\n",
    "            optim=optimize.minimize(maximand,x0,method='COBYLA',constraints=cnstrs)\n",
    "            if not optim.success:\n",
    "                raise RuntimeError('Failed to optimize for W=%1.4f: %s'%(W,optim.message))\n",
    "            else:\n",
    "                cstar[0,i]=optim.x\n",
    "                V1[0,i]=-optim.fun\n",
    "                x0=optim.x #use previous optimum for starting value\n",
    "        return V1, cstar\n",
    "    \n",
    "    if plotting:\n",
    "        # prepare to make plots \n",
    "        fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "        plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax1.set_title('Value function convergence with VFI')\n",
    "        ax1.set_xlabel('Cake size, W')\n",
    "        ax1.set_ylabel('Value function')\n",
    "    \n",
    "    V0=np.zeros((1,model.ngrid)) #initial value function\n",
    "    for i in range(model.maxiter):\n",
    "        V1,c=bellman(V0)\n",
    "        if plotting and (i%5==0):\n",
    "            # plot all but the first point for better viewing\n",
    "            ax1.plot(np.squeeze(grid[0][1:]),np.squeeze(V1[0][1:]),linewidth=2.5)\n",
    "        if np.max(abs(V1-V0))<model.tol:\n",
    "            print('Convergence achieved after %d iterations'%i)\n",
    "            break\n",
    "        V0=V1\n",
    "    else:\n",
    "        print('No convergence in %d iterations: maximum number of iterations achieved'%model.maxiter)\n",
    "    return grid, V1, c\n",
    "\n",
    "m = cake()\n",
    "w,v,c = solve3(m)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m = cake()\n",
    "# m.ngrid=200\n",
    "w,v,c = solve3(m,plotting=False)\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Value function')\n",
    "ax1.plot(w[0,1:].squeeze(),v[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.avalue(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Policy function')\n",
    "ax1.plot(w[0,1:].squeeze(),c[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.apolicy(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation\n",
    "Directly atacking continuous choice problem is hard:\n",
    "- VFI becomes very slow\n",
    "- Not robust (will be even worse in more complicated problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Endogenous grid point method (EGM)\n",
    "\n",
    "**What if no root-findnig is necessary during VFI?**\n",
    "\n",
    "Model-specific solution method that is VERY fast and accurate\n",
    "\n",
    "Conditions:\n",
    "1. Consumption-savings (stock and flow) model structure\n",
    "2. Invertible marginal utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Euler equation\n",
    "First order condition (FOC) of the Bellman equation w.r.t. $c$\n",
    "$$\n",
    "0 = u'(c_{t})+\\beta \\frac{\\partial V(W_{t+1})}{\\partial c_{t}} =\n",
    "u'(c_{t})+\\beta V'(W_{t+1})\n",
    "\\underset{-1}{\\underbrace{\\frac{\\partial W_{t+1}}{\\partial c_{t}}}},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow u'(c^\\star_{t})=\\beta V'(W_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Euler equation\n",
    "From the Envelope theorem we have\n",
    "$$\n",
    "V'(W_{t}) \n",
    "=\\frac{\\partial}{\\partial W_t}\\big[ u(c_t)+\\beta V(W_{t+1}) \\big] \\Big|_{c_t^{\\star}}\n",
    "=\\beta V'(W_{t+1}) \\underset{1}{\\underbrace{\\frac{\\partial W_{t+1}}{\\partial W_{t}}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Euler equation\n",
    "Shift one period over, combine and plug back into FOC\n",
    "$$\n",
    "u'(c^\\star_t) = V'(W_t) \\Rightarrow u'(c^\\star_{t+1}) = V'(W_{t+1}) \\Rightarrow\n",
    "$$\n",
    "\n",
    "$$\n",
    "u'(c^\\star_{t})=\\beta u'(c^\\star_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea of EGM \n",
    "&#128214; Carroll 2006, _Economics letters_\n",
    "\"The method of endogenous gridpoints for solving dynamic stochastic\n",
    "optimization problems\"\n",
    "\n",
    "- Instead of searching for optimal decision in each point of the state\n",
    "space (traditional approaches)\n",
    "- Look for the state variable (level of assets) where arbitrary chosen decision (consumption $\\rightarrow$ savings)  would be optimal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### EGM algorithm\n",
    "\n",
    "1. Start with $c_T^{\\star}=W_T$. In each period $t=T,T-1,..,1$  \n",
    "(or time iteration $t$):\n",
    "2. Take a guess $A$ = current period savings ($A=W_{t}-c_{t}$)  \n",
    "(these guesses come from fixed or adaptive grid)\n",
    "3. Intertemporal budget constraint: $A \\rightarrow W_{t+1}$\n",
    "$$W_{t+1}=W_{t}-c_{t}=A$$\n",
    "4. Policy function at period $t+1$: $W_{t+1} \\rightarrow c_{t+1}$\n",
    "$$c_{t+1}=c_{t+1}^{\\star}\\big(W_{t+1}\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5. Inverted Euler equation: $c_{t+1} \\rightarrow c_{t}$\n",
    "$$c_{t}=\\big(u^{\\prime}\\big)^{-1}\\big( \\beta u'(c_{t+1}) \\big)$$\n",
    "6. Intratemporal budget constraint: $c_{t}+A=W_{t} \\rightarrow c_{t}\\left(W_{t}\\right)$\n",
    "$W_{t}=c_{t}+A \\rightarrow c_{t}^{\\star}\\left(W_{t}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation\n",
    "- No root finding, simple direct computation of the optiomal policy\n",
    "- Value function is not needed, although can be computed along side\n",
    "- Resulting funcitons are defined over irregular endogenous grid $\\rightarrow$ potential issues in multiple dimensions\n",
    "- Interpolation of __policy function__ which has much lower curvature!\n",
    "- Euler errors are zero at the grid points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applicability\n",
    "1. Marginal utility must be invertible\n",
    "2. There must be the **post-decision state variable** $A$ which serves as a _sufficient statistic_ for period $t$ state $W_t$ and decision $c_t$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "V(x) &=&\n",
    "\\max_{\\sigma \\in \\Sigma} \\Big\\{ u\\big(x,d\\big) \n",
    "+ \\beta \\mathbb{E} \\big[ V(x')  \\big| x, d \\big] \\Big\\}\n",
    "\\\\ &=&\n",
    "\\max_{\\sigma \\in \\Sigma} \\Big\\{ u\\big(x,d\\big) \n",
    "+ \\beta \\mathbb{E} \\big[ V(x')  \\big| A(x,d) \\big] \\Big\\}\n",
    "\\end{eqnarray}\n",
    "\n",
    "3. Current period state must be recoverable from decision and post-decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "def solve4(model,plotting=True):\n",
    "    '''Solve cake eating problem by EGM'''\n",
    "    machine_epsilon=np.finfo(float).eps #smallest positive float number\n",
    "    ngrid=model.ngrid\n",
    "    #(1 by ngrid) grid for post decision variable A\n",
    "    grid=np.linspace(machine_epsilon,model.Wbar,ngrid).reshape(1,ngrid)\n",
    "        \n",
    "    def egm_step(W0,c0,v0):\n",
    "        '''EGM step: input/output grid, policy, value for next period/current period'''\n",
    "        Wnxt = grid #size of cake next period\n",
    "        cnxt = np.interp(Wnxt,np.squeeze(W0),np.squeeze(c0)) #next period optimal consumption\n",
    "        rhs = model.beta*model.marginal_utility(cnxt)\n",
    "        c = model.inverse_marginal_utility(rhs)\n",
    "        W = c + grid\n",
    "        v = model.utility(c) + model.beta*np.interp(Wnxt,np.squeeze(W0),np.squeeze(v0))\n",
    "        return W,c,v\n",
    "    \n",
    "    if plotting:\n",
    "        # prepare to make plots\n",
    "        fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "        plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax1.set_title('Value function convergence with VFI')\n",
    "        ax1.set_xlabel('Cake size, W')\n",
    "        ax1.set_ylabel('Value function')\n",
    "    \n",
    "    #initial grid, consumption and value\n",
    "    W0=grid\n",
    "    c0=grid\n",
    "    v0=model.utility(grid)\n",
    "    #loop over EGM steps\n",
    "    for i in range(model.maxiter):\n",
    "        W1,c1,v1=egm_step(W0,c0,v0)\n",
    "        if plotting and (i%5==0):\n",
    "            # plot all but the first point for better viewing\n",
    "            ax1.plot(np.squeeze(W1[0][1:]),np.squeeze(v1[0][1:]),linewidth=2.5)\n",
    "            plt.xlim(right=model.Wbar) \n",
    "        # note complex convergence criterion!\n",
    "        dif=np.interp(grid,np.squeeze(W1),np.squeeze(c1)) - np.interp(grid,np.squeeze(W0),np.squeeze(c0))\n",
    "        if np.max(abs(dif))<model.tol:\n",
    "            print('Convergence achieved after %d iterations'%i)\n",
    "            break\n",
    "        W0=W1\n",
    "        c0=c1\n",
    "        v0=v1\n",
    "    else:\n",
    "        print('No convergence in %d iterations: maximum number of iterations achieved'%model.maxiter)\n",
    "    return W1, v1, c1\n",
    "\n",
    "m = cake()\n",
    "# m.ngrid=50\n",
    "# m.maxiter=5\n",
    "w,v,c = solve4(m)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def egm_step(W0,c0,v0):\n",
    "        '''EGM step: input/output grid, policy, value for next period/current period'''\n",
    "        Wnxt = grid #size of cake next period\n",
    "        cnxt = np.interp(Wnxt,np.squeeze(W0),np.squeeze(c0)) #next period optimal consumption\n",
    "        rhs = model.beta*model.marginal_utility(cnxt)\n",
    "        c = model.inverse_marginal_utility(rhs)\n",
    "        W = c + grid\n",
    "        # linear interpolation\n",
    "        v = model.utility(c) + model.beta*np.interp(Wnxt,np.squeeze(W0),np.squeeze(v0))\n",
    "        # cubic splines\n",
    "#         interp=interp1d(np.squeeze(W0),np.squeeze(v0),kind='cubic',fill_value='extrapolate')\n",
    "#         v = model.utility(c) + model.beta*interp(Wnxt)\n",
    "        # log-transform + linear\n",
    "#         tr = lambda x: np.log(x)\n",
    "#         itr = lambda x: np.exp(x)\n",
    "#         v = model.utility(c) + model.beta*tr(np.interp(Wnxt,np.squeeze(W0),itr(np.squeeze(v0))))\n",
    "        return W,c,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m = cake()\n",
    "# m.ngrid=1000\n",
    "w,v,c = solve4(m,plotting=False)\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Value function')\n",
    "ax1.plot(w[0,1:].squeeze(),v[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.avalue(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12,8))\n",
    "plt.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "ax1.set_title('Solution')\n",
    "ax1.set_xlabel('Cake size, W')\n",
    "ax1.set_ylabel('Policy function')\n",
    "ax1.plot(w[0,1:].squeeze(),c[0,1:].squeeze(),linewidth=2.5,label='Numerical')\n",
    "ax1.plot(w[0,1:].squeeze(),m.apolicy(w[0,1:].squeeze()),linewidth=2.5,label='Analytical')\n",
    "plt.legend(loc=4)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which DP solution algorithm will you choose for your project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further learning resources\n",
    "* QuantEcon DP section https://lectures.quantecon.org/py/index_dynamic_programming.html\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
